{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification Prototyping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34rVf9SGL--I",
        "colab_type": "text"
      },
      "source": [
        "# Initialize globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5jf1ksbhM1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, glob, re\n",
        "\n",
        "project_path = 'C:/Users/vap43/Documents/GitHub/reddit_comment_classification/'\n",
        "TRAIN_DATA_PATH = project_path + \"data/data_train.pkl\"\n",
        "TEST_DATA_PATH = project_path + \"data/data_test.pkl\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5VRVSw0h5pP",
        "colab_type": "text"
      },
      "source": [
        "# Import the text and classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3EFl9T-igp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_pickle(TRAIN_DATA_PATH)\n",
        "test_data  = pd.read_pickle(TEST_DATA_PATH)\n",
        "\n",
        "nb_X_Train = len(train_data[0])\n",
        "All_X = np.concatenate((np.array(train_data[0]),np.array(test_data)))\n",
        "y = np.array(train_data[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUq8uhNitMCJ",
        "colab_type": "code",
        "outputId": "ae950c29-7328-477d-8b2e-c26169ce0d7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(All_X.shape)\n",
        "print(nb_X_Train)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000,)\n",
            "70000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewlSnlMdpM3a",
        "colab_type": "text"
      },
      "source": [
        "# Pre-process the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01kZ5H8ov2SI",
        "colab_type": "text"
      },
      "source": [
        "Remove stop words and stem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T9JISjh_QpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stop_words_list = stopwords.words('english')\n",
        "pattern = re.compile(r'\\b\\w\\w+\\b')\n",
        "\n",
        "for idx, sentence in enumerate(All_X):\n",
        "  #All_X[idx] = \" \".join([stemmer.stem(word) for word in re.findall(pattern, sentence.lower()) if word not in stop_words_list])\n",
        "  All_X[idx] = \" \".join([word for word in re.findall(pattern, sentence.lower()) if word not in stop_words_list])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_YrdTYfvywF",
        "colab_type": "text"
      },
      "source": [
        "Count the terms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT-js4KyvObo",
        "colab_type": "code",
        "outputId": "f9c4bd5f-9fc7-4b9d-ff69-3684dae8879e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "  ngram_range=(1, 1),\n",
        "  min_df=3,\n",
        "  max_features=None,\n",
        ")\n",
        "All_X_Counts = vectorizer.fit_transform(All_X)\n",
        "print(All_X_Counts.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100000, 31953)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cbjQsTkvxjy",
        "colab_type": "text"
      },
      "source": [
        "Weight the terms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIoo9U7-vP_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "All_X_ifidf = tfidf_transformer.fit_transform(All_X_Counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-uaKq8IM4j0",
        "colab_type": "text"
      },
      "source": [
        "Split out the Train/test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fecyI4aCuslL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = All_X_ifidf[:nb_X_Train,:]\n",
        "Kaggle_Test_X = All_X_ifidf[nb_X_Train:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X2yIHi6M3ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Train_X, Test_X, Train_y, Test_y = train_test_split(X,y, test_size=0.1, random_state=0, stratify=y)\n",
        "Train_X, Train_y = X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ2ePnEhPKoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# print(Train_X.shape)\n",
        "# print(Train_y.shape)\n",
        "\n",
        "# clf = MultinomialNB(alpha=0.3)\n",
        "# clf.fit(Train_X, Train_y)\n",
        "# clf.score(Test_X, Test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnFSfbhHeCob",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Try out keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFu-rKUaoDyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "# integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(Train_y.reshape(-1,1))\n",
        "#onehot_encoded_test = onehot_encoder.transform(Test_y.reshape(-1,1))\n",
        "y_onehot = onehot_encoder.transform(y.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DWMw4LFeE3v",
        "colab_type": "code",
        "outputId": "ba1a285e-8cc6-4d5b-d391-1f0df222b395",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, BatchNormalization, GaussianNoise\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adagrad, Adam\n",
        "from keras.constraints import max_norm\n",
        "\n",
        "model = Sequential([\n",
        "  # Input layer\n",
        "  Dense(\n",
        "    1024,\n",
        "    use_bias=False,\n",
        "    input_shape=(Train_X.shape[1],),\n",
        "    #kernel_regularizer=l2(0.0001),\n",
        "    kernel_constraint=max_norm(3.),\n",
        "  ),\n",
        "  BatchNormalization(),\n",
        "  Activation('relu'),\n",
        "  #Dropout(0.5),\n",
        "\n",
        "  # # Hidden Layer\n",
        "  # Dense(\n",
        "  #   512,\n",
        "  #   use_bias=False,\n",
        "  #   kernel_regularizer=l2(0.001),\n",
        "  #   kernel_constraint=max_norm(3.),\n",
        "  # ),\n",
        "  # BatchNormalization(),\n",
        "  # Activation('relu'),\n",
        "  # Dropout(0.5),\n",
        "\n",
        "  # Output layer\n",
        "  Dense(\n",
        "    20,\n",
        "    use_bias=False\n",
        "  ),\n",
        "  BatchNormalization(),\n",
        "  Activation('softmax'),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  Adagrad(learning_rate=0.003),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        ")\n",
        "\n",
        "#model.fit(Train_X, onehot_encoded, epochs=1, batch_size=64, validation_data=(Test_X,onehot_encoded_test))\n",
        "model.fit(X, y_onehot, epochs=1, batch_size=64)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "70000/70000 [==============================] - 58s 828us/step - loss: 1.8374 - accuracy: 0.4960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x1d7d146a348>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIW3xGQLu5_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_onehot = model.predict(Kaggle_Test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEI2E05OvfFD",
        "colab_type": "code",
        "outputId": "e11ba9c5-124e-4a24-b6f2-6cce0152a3e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_kaggle = onehot_encoder.inverse_transform(y_onehot)\n",
        "y_kaggle = y_kaggle.squeeze()\n",
        "print(y_kaggle.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXdwcImjv9rD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_and_save_submission(predictions, file_name=\"submission.csv\"):\n",
        "    ids = [i for i in range(len(predictions))]\n",
        "    sub_df = pd.DataFrame(data=list(zip(ids, predictions)), columns=[\"Id\",\"Category\"])\n",
        "    sub_df.to_csv(file_name, index=False)\n",
        "\n",
        "create_and_save_submission(y_kaggle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmQZgwBgP0CJ",
        "colab_type": "text"
      },
      "source": [
        "# Create a list of algorithms to test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZPrVAIK9ARL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, VotingClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "names = [\"Decision Tree\", \"Forest\",\"KNN\",\"NB\", \"SVC\", \"AdaBoost\", \"LogisticRegression\", \"Bag\", \"Vote\", \"NN\"]\n",
        "\n",
        "classifiers = [\n",
        "  DecisionTreeClassifier( **{'min_samples_leaf': 0.01, 'max_features': 1.0, 'max_depth': 100}),\n",
        "  RandomForestClassifier( **{'n_estimators': 30, 'min_samples_leaf': 0.001, 'max_features': 1.0, 'max_depth': 100,}), #26.2% acc\n",
        "  KNeighborsClassifier(   **{'weights': 'distance', 'p': 1, 'n_neighbors': 40}),\n",
        "  MultinomialNB(          **{'alpha': 0.3}),\n",
        "  LinearSVC(              **{'dual': False, 'C': 0.1}),\n",
        "  AdaBoostClassifier(     **{'n_estimators': 100, 'learning_rate': 1.0}),\n",
        "  LogisticRegression(),\n",
        "  BaggingClassifier(base_estimator=LinearSVC(**{'C': 0.1})),\n",
        "  VotingClassifier(estimators=[\n",
        "                               ('lsvc', LinearSVC(C=0.1)),\n",
        "                               ('mnb', MultinomialNB(alpha=0.3)),\n",
        "                               ('nn', MLPClassifier(**{'max_iter': 1, 'hidden_layer_sizes': (256,), 'batch_size': 64})),\n",
        "                               ]), # 57.2% acc\n",
        "  MLPClassifier(**{'max_iter': 1, 'hidden_layer_sizes': (256,), 'batch_size': 64}), # 57.2% acc\n",
        "]\n",
        "\n",
        "for name, clf in zip(names, classifiers):\n",
        "  if name not in ['']: continue\n",
        "  scores = cross_val_score(clf, Train_X, Train_y, cv=4, scoring='accuracy',n_jobs=-1)\n",
        "  print(name + ' Accuracy: ' + str(scores.mean()) + ' | std = ' + str(scores.std()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sqYjdYXCAs7",
        "colab_type": "text"
      },
      "source": [
        "# Choose the best hyperparameters for each algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db2-WzUqCFZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "b1b45f8d-6cbe-4f06-c73a-a2d847811dbb"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from IPython.display import Audio\n",
        "sound_file = 'C:/Users/vap43/AppData/Local/BlueJeans/current/Assets/Sounds/recording_stopped.mp3'\n",
        "\n",
        "Tree_param = {\n",
        "  'max_features'    : [0.01, 0.03, 0.1, 0.3, 1.0],\n",
        "  'max_depth'       : [3, 10, 30, 100],\n",
        "  'min_samples_leaf': [0.01, 0.03, 0.1, 0.3],\n",
        "}\n",
        "\n",
        "Forest_param = {\n",
        "  'n_jobs'          : [1],\n",
        "  'n_estimators'    : [10, 30, 100, 300],\n",
        "  'max_features'    : [1.0],\n",
        "  'max_depth'       : [3, 10, 30, 100],\n",
        "  'min_samples_leaf': [0.001, 0.003, 0.01, 0.03, 0.1],\n",
        "}\n",
        "\n",
        "knn_param = {\n",
        "  'n_neighbors' : [1,3,10,20,40,60],\n",
        "  'weights'     : ['uniform', 'distance'],\n",
        "  'p'           : [1, 2],\n",
        "}\n",
        "\n",
        "nb_param = {\n",
        "  'alpha' : [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4]\n",
        "}\n",
        "\n",
        "svc_param = {\n",
        "  #'kernel'        : [\"linear\"],\n",
        "  'C'             : [0.01, 0.03, 0.063, 0.83, 0.1, 0.12, 0.15, 0.2, 0.3, 1.0],\n",
        "  'dual'          : [False],\n",
        "}\n",
        "\n",
        "ada_param = {\n",
        "  # 'n_estimators'  : [20, 50, 100],\n",
        "  # 'learning_rate' : [0.01, 0.03, 0.1, 0.3, 1.0],\n",
        "  'n_estimators'  : [100],\n",
        "  'learning_rate' : [1.0],\n",
        "}\n",
        "\n",
        "log_param = {\n",
        "  'penalty'     : ['l2'],\n",
        "  'solver'      : ['lbfgs'],\n",
        "  'multi_class' : ['auto'],\n",
        "  'C'           : [0.03, 0.1, 0.3, 1.0, 3., 10.],\n",
        "  'max_iter'    : [10, 30, 100, 300]\n",
        "}\n",
        "\n",
        "bag_param = {\n",
        "    'base_estimator' : [LinearSVC(C=0.1), LinearSVC(C=0.3), LinearSVC(C=1.0)],\n",
        "    'max_features'   : [0.3, 0.6, 1.0],\n",
        "    'max_samples'    : [0.3, 0.6, 1.0],\n",
        "}\n",
        "\n",
        "vote_param = {\n",
        "    'estimators' : [[\n",
        "      ('lsvc', LinearSVC(C=0.1)),\n",
        "      ('mnb', MultinomialNB(alpha=0.3)),\n",
        "      ('nn', MLPClassifier(**{'max_iter': 1, 'hidden_layer_sizes': (256,), 'batch_size': 64})),\n",
        "    ]],\n",
        "    'n_jobs' : [-1],\n",
        "    #'voting' : ['hard', 'soft'],\n",
        "}\n",
        "\n",
        "nn_param = {\n",
        "    'max_iter'           : [1],\n",
        "    'hidden_layer_sizes' : ((64,), (128,), (256,), (512,), (1024,)),\n",
        "    'batch_size'         : [64],\n",
        "}\n",
        "\n",
        "grid_parameters = [\n",
        "  Tree_param,\n",
        "  Forest_param,\n",
        "  knn_param,\n",
        "  nb_param,\n",
        "  svc_param,\n",
        "  ada_param,\n",
        "  log_param,\n",
        "  bag_param,\n",
        "  vote_param,\n",
        "  nn_param\n",
        "]\n",
        "\n",
        "for name, clf, grid_params in zip(names, classifiers, grid_parameters):\n",
        "  if name not in [\"NB\", \"SVC\"]: continue\n",
        "  gd_sr = RandomizedSearchCV(\n",
        "    estimator=clf,\n",
        "    param_distributions=grid_params,\n",
        "    scoring='accuracy',\n",
        "    cv=4,\n",
        "    n_jobs=-1,\n",
        "    n_iter=20\n",
        "  )\n",
        "  gd_sr.fit(Train_X, Train_y)\n",
        "  best_parameters = gd_sr.best_params_\n",
        "  best_result = gd_sr.best_score_\n",
        "  print(name, best_result, best_parameters)\n",
        "\n",
        "Audio(sound_file, autoplay=True)\n",
        "# Bag 0.5571428571428572 {'max_samples': 0.6, 'max_features': 1.0, 'base_estimator': LinearSVC(C=0.1"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\vap43\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 8 is smaller than n_iter=20. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "NB 0.5673714285714285 {'alpha': 0.25}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\vap43\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:266: UserWarning: The total space of parameters 10 is smaller than n_iter=20. Running 10 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SVC 0.5618571428571428 {'dual': False, 'C': 0.15}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
              "                    <source src=\"data:audio/mpeg;base64,SUQzBAAAAAAAI1RTU0UAAAAPAAADTGF2ZjU4LjIwLjEwMAAAAAAAAAAAAAAA//NYwAAAAAAAAAAAAEluZm8AAAAPAAAANgAAF3wADBAQFRUaGh4eIyMnLCwxMTU1Ojo+PkNDSExMUVFVVVpaX19jY2hsbHFxdnZ6en9/g4iIjY2RkZaWmpqfn6SoqK2tsbG2tru7v7/EyMjNzdLS1tbb29/f5Onp7e3y8vb2+/v/AAAAAExhdmM1OC4zNQAAAAAAAAAAAAAAACQDsAAAAAAAABd8ZFwZwwAAAAAAAAAAAAAA//M4xAAKoCYsXsMGAAYUklwADpoJGaBIBw8eCCBQyGCIniAEJ+TqcXf26uUd+frf//v3J9/LvoUCAo5I2DhhFgXPCgjDNCgub+vik42REQwNoiyeZ0GO/7b+WXo9n6P1IHUK9Pf3+z/mmkEx//M4xDQMsEJAXtJADL1UMZC8E3QUEo+iQGNFAf153ALJCV5D0UmIj5DsKFWRjzFDX5t4vs0obYPUrIpL+cPFFLCQ0F0DdrJwhbutHyUasvRT7CG0ulG1mca9P9Xv2ORoAIAiOW22gFup96sI//M4xGAVANYcAOPQNByiSAIPKcaeIGRXspt2pMp9Nyf/3/T9Po//8Z/p7tVCFOqDS8gKWMsEMIAVheKORB52oxGbv6u8zsyLVyxYluPb+kGMIKuI2Mf0EWbD5ZhOJNi1Jv7Mn+8j2Lp+xdlS//M4xGsK6CpNnsoEBL9ztjt62rM/9FU1ifwcQDJBqMQBk64GwCcjAQMb0oAKcJowjER4ZYg+mswcQgVmAhRBTcJCaCmDwoxHyDD0roRljLwmTwGYeCml5lIZLF7M/y9L+nH+V9nZVJFn7lin//M4xJ4SCLIwFVowANzsGY0CuN6xi9PG1b4vaBqkS9JvSm/rW87z7Zxf+f1r7o0dzv89r0GF1Fck9lPnVb93xPkzf7Wncywl/QMqkSQVABBCMIwjMFEAFjKMMTWMTRTL2mz4aGDAzG+oGmCo//M4xLQkicYgAZx4AXBg8FgYEgZaZhmKZwKIJguSJrCAJHhccjUBCgmCkhixqKCpvQgjQhPL1zoECwwnHQomQx0LAxEMAAgEq2KmkJd8QghMEl9kLCwAKaFs1gCghdCHLMvnM+wuan62rsVv//M4xIAmYRpQBZ3YANBfFwsEHBEWsPNYt//lEN+/6U/W//+tFKaacAGVTbbYBrlJacCw5ZCJQSHMJmrDCERZRqEbxmoGkErh+/lH3sAyHaLmoy+ngojgJWAsAEAQRWlzYkMmgK9zYKs6jb0+//M4xEUmQs6pn9h4AnW4s8nfscJDJnl4FKa+1BJE03s89b3ZJX9/e79npunxrN//vGr/Ob/Gbx9fE9/6e//gUvT33Td9///7+f//9fEDV/nw7w77prdPumY8N/HCE4IHaMMIKSCSAM72L/5F//M4xAsXeV7NfnleshHgh2IXgvQ6S9zqfmbmMbmNhEFYysZhITMxQuSwv0RKYdHOEHURfD8JqOEBHEgAIAVA/GVRz4TigeF8IQ6h3+HlX8gDkzk///1UcvISFKf5Rxwne/n//9VsMyYpP71t//M4xAwWCZqkAMFYsLIXWAMFnlArPhIT/iPrMYW5hqlq9Prrp1GST13rWSiS62DURVLXLnlwJDjymzN15XQrM3fynRuXm96UhDnfz/b0urEBAHz4P7gfspeqcAEdcgKYnBo6peG+G4BiBVLD//M4xBIZOX6dv08wAJS7WFUfqyntPq2bZoz6V/no4KuXlqqt/7VVPjf1VeWr61Oi2//+cp+9VRYKRBQkqAo2CJ5Y4HREWPSKn5ZjeVkeIgaCuIiQFlaxEGmHlHv+Rh0rAJAIAbQo4GmxBnr9//M4xAwX6vpoK5mQADNqV5uSSYnI1etwxFEklqZyKHi//jMIm5d/8QnFjJkXOl/+B2oNj4yYjw1N+1X+eL5uaKQL///5fdBBjdP////6DF83TLhcNCf/////L5uTjFw/Sk9cRiJFXN6Uu+u1//M4xAsTcPaIAY9gAMOWSKzctlewmFxCJLcNnVlfstZKTCl4sFQdmzEEAajwiDUK0JkeB2XxMunZY6WDDEGGioQ1zl1//q9f1+bHhMAt+AJ262NxzbcUAVXXvSqGqd1E7THlzwRgFQRXhURw//M4xBwUuLbWX9pIAq0XqvdDjqyK1ZxuXCMTydPSdWJcjkFpupqK0AyqxAWAxUgOJGwWStdCj/gmBwWOvi3Av/1QKDUJD3ABoDxVuY2bdGghMkoypzjBfqW6q1X1C4hlhAg8iSag7d/HKUwA//M4xCgVGZ6QtMgHZIShEKgsYQRdBtYBl2rFqU1rFfPD///53Weef/2v3sxbooYBgSBNe3/nJw+hKrDiAJdZIAASoyWpaFQ9wM4WiloWoEmNITUhfrRLhIBfG+/mA5gTCGnfs/i0wLAND/Lz//M4xDIUYi7BvmsPKjN8OCoKDH/cxlhIf9T3UME/U00452/6p///cqNglGTKgAAA28QYZ9f/OrieAJqGuP/f2V6IFNC+HE5a/+X7OnFpOqGtrUgASB+kFWqLs3eSlh94FSOpE4lGe43qccgM//M4xD8TqVKxuH4HJXECAJxIlxeksOkSJED0sUUQKQEQACSfzD/wutPHpSS/zWDWEvFqgKhxEmtT5v9Gx2o5/7TWTFLgGA0TNMlUARowRMSZK9CIBoDfE0JepoLPhTlzOxUOMSI4hTHgQSMM//M4xE8UyRqlXsJezCP///Sq5AKdFKOAAkrA3+DCL4OFDZYubJw6IbkroULO3lMQ7B3SJvpX/iiTbWn/3UVX8q1L3fDGJCVostz8/H/6TB4cAsNYzF2Fz+bLYzn7f//nQQBw/4nqgDHCbtv5//M4xFoU0kLBnnoE/kWD+fT+j8chemJRP0+OAl4/XGCr1twfRa5pXAhjTXKUiuzXKrKzMosKwq6NgnZCpY+48NvxoZ9hnoXEGmYeYcOJmbv8WLxwnuqd7d2v0Q4AiFi3hDgK57jthcSS+u0m//M4xGUT+bqsynhNDHU6d1Xm22fwgCAl4dP81X43+lVfRvlaM2rH/+xuTRmedrrn/PiHuqjUvZUf////xJRYKgkBDsUNMHeACyiKlYvNIVnn0ASYBCEa8gmwFBbpx3AaZtze4uhJy/qHh/Cx//M4xHQU0lLFlnjK+la+4DE7f6ZkE2/JIeJMurDbypmWbDv9RqLGZEFwsDLxgF/3V1/DSBcNPq/zw5VVne5GCJAGu8/6qHEShnrCmT+A1629RJW5Pq32rJHfzkigGn9cQAFdwEBHJsgN6sGD//M4xH8TUKq2fkvSGBOUxKGdlp/5Tf+VvLKxQEFaf//UdBQKhqoGgqd+WBqWqbUS25LFJaAmfb1DkraOGtnq/1IKXVvV0cAzX92hZ33uNfbamKa7cTpnztt1SQhy2RmZejp18hCEO6fkJzn5//M4xJAUcaKlnsGEys4GcXg+D5Ss/ggH4gcgEHQ+c//+6s6lKm4TZRAjk5DBgoZWEcqmpYMf5wYr00AipOCGzhKhIQNDIQvJyX5DP9uf/zk/+GbU09iRBm7b4arbRQBVMxyPItXKxslMopyd//M4xJ0VWaKpvsJElkO29tps+1//J8gNnEViiA2DuukSzCRDh5abHEa2fL+e0tkvIQm3rNpiN7cIeA//nJk+hGO3/PeIn7uOQMcWAOZqJUUTcBCH9MIYOukDIYQtQNhnH1zJQTo4r//0KGpQ//M4xKYU6h54CtDMnM95LUYRdwCms5qn2hyIUY8X5LHDtFQ2dmmAn9Nv6ZyC4D865V9uaVlLhj9RmbN+VKG1RBOW/mcZMz+39VYT19oGW17SzOOzszgd9w46H57keUpcV15V58gUeGnOf2OV//M4xLEUKdp8AMpGWEfKhwYok24yoSBiCYeDRhIxhAVRJSMXWPn5FTUS+3utKUljEJBoFumRVd0QED4FFJPg7LNokFggsls7xf8QDANMMwBm72s54AODyjf1T4QwdUbHRYhacWv7IgQhK/+k//M4xL8dOaaiXtMHKAL4jsZyXcHOWTTjMpBDVR3+YavVTlv8DTl+BQ0evyHAVOXsOAgBfK6ECkx0WH8foKH/8vH+//yLj90P4f757QnTQn58H2zU0CrADdgQl4ZatS0S03mc+tBBoRSSfk+U//M4xKkjwlKi1tPREG13uidauTPf+1lKSvWt/diKNOWef5rlQGv9diMoEQxbDLdGLgi+6CK3iFLZ4Ok9U+UL/JfU34RHegk/HSVrigCZI2jBcOZtRwk76mP0GpZ/d//e4UH7nCcBycI7qZ/Y//M4xHkhqz62VsHTW19MYpOcHJm51GczJ+davHCmmtLc2hAZpr0uiHoaMX0S5pjeUUbMFhE+CDNsWadlTBYnM6GARn1IBP4UT0UBL2Q3lKVtECt6t9H+rfQz2ozCqIFQMKsHuakzFQlpOeb1//M4xFEW6cq6XniG+GIEkZl9mjg/9Bd9qbdktcb/wCQWrcko6fkVq/q35vxZnm1mJtN5+7SnlJSnjinb/3g3drHsjM3/+v7+qUem/1kv1VZ/b5rLq5ZSLRFVhCt2WkLcy163UJm42dpGGvEw//M4xFQW80LJvECRd6UeKApKDgxVckktkkbboACIuOqHr0ftb1Pg9Nb2ERsjhLTRO5TuS9WKp5fDCDmxWqIIOir/5WoKhhe7KyUtM7VtMhGfSWWqoOMcAK2812pZbI0VIrUdX//uxipwW27a//M4xFcUicLCXGGK5usk5ABoyaJRf9htqr61GRBQxSB0JNFNQ3pgakqGOqxqGqaK9NMv/8WUZrS/+FV/6dJj/1cvO2qy2ZTChWsESbHsvX/yVRX9byNG1S9RYhVMOUAbfWIACSjiQq0kv1JJ//M4xGMUmdrGXDmGWiKK0UWUk////tMbUrf8rGUBdaGdSlM/o5XLKXspf8zlKyOpnoYxjaslcr0M6l/oaU36GrMrZfUqPsZ+hpjSlYy0MbcK0qogwwMCsVCgRisWCgFa4N9dB5CFfujgBEEM//M4xG8VSz6Nv1AQAf1ZoB8EN5mqDkTfycQR5idjzHoUSQ+PAc6ZoXzRy4i/5uXEzMmGjKjwLhc/pMm1A4Wlw0LhcT/88bl9SbGDLLh5YmCJfoL//Kigt2JQzcRguqHkxxaCknSQUZm3//Ew//M4xHgmy86pv49oACTIJw1KJECqBcwtZSGgbBMxgUktJaJwxZFSS///+mn//+su1V5S6mppcgQIr3suS6LB2pPymgJ8BoZmSlCuqHE0DQZ3/YUCGKIKtoRMKj9bsHh3trnB43LDYlqz9Q8f//M4xDsaCa6kAdhgAIhiOVDMstuF0jDqVlX0eia/aVts9StmZ99bGzay9GseTMLYYrw+PLk0CRP/9KqrTsYbuAZtmAQAIKzqCJ+EODKq2SoonO9XY1UhrrbOciRUMWI8DBVOemgSq7MKSKIK//M4xDEUmO7F9oPMOEyOZrSySDINPMi65jR8UesDFhcd+08fHDhhgcuwqQ///fWHkosZAAvTZwOwNErJXGhS11hOEhQnVGFL0OEgaS8os+PB2iYWIj2rN2ENS64fnBtZ99x7+r+sqkOiHruz//M4xD0UaaK59nsEtCddLJ/9a2QwJzgU+kAvFQbWRe2rSs65sAN0l4AOmPaCQ51GoTMelx8g+EKUU6kR7LS4sGJJMBAEjJ6U5zJmeQuTSBcAQoitvhkOVjmW5zKyE6apN/e9XmQNcKOO551t//M4xEoUyarGPnmEzEu6lBRbrCAbAlUWaBC6ckEeeA4A2VXvJsg/4+MAsonyAByZoVUey8B23yltPWO3M2qn9qVq5KJfR9BTap0flfVtDNp7emUGcBViw1RtoUbGEXebGhH//6N1qReRRant//M4xFUUQZa5lnsEeq7UA5QDZVxSdKrZoSaVHSVn1Jn0iJtzqgka8rQ1rJvNM0FGwzMLXWzeoKRNuIIe0dRR35V/NXGrNtcrEOaqrtkirkB2W86vOvV4Vz3///BqtT/xzUKQYMNOCAhlOQMD//M4xGMVIZq5nnpQOjZ20sThdZYcAA1qRaUKBUUTgWmZVAM7L2Aj4liKTC5KRB9tDGLElq26Rb5ocjaFwiLBud1G1+WWlFn/////9KoBEA8EfgFlhw5yfzPkgtyqU/9+vZpes3cyHsJ96CCy//M4xG0TSOI4AVpIAFBwiWhPQ5XxwDkAdYBvg7wVoFaC2heQb34CIBXCAJgPQlA6gFUAEUSYL0MN/HOXzccg9CUHOSI9R6mQ9jZf/GHJcTAehQHOPc3JRFDMUki8j/+aMmm/8ukiZF4kjEul//M4xH4myv5kC5hoANSMi8Y///ZTG6aZoggbppoIl1IvF4FTp6z/wx/0VTyqfMjBcyyjEBpmoyg4MOAkzKV6rvf5nLww9LcpErIzYnGV02KxWNbtSzpHcWI5fUB6czsGyLyE4yqWWaH63Jkn//M4xEEhWhIoAZx4AJDXrVCN10xyZzZ1qXFYb1WvoTlWX6rfxv/jevTd8vfX2xvP1jOfjH18/P3PmLr5r7QsjSjaqatITgzFwCoU2XB3yyLCypF1rbvmBDJv+fvRbH/ry+GXZ4SM4RAFAO8a//M4xBobe86EAZg4AA0Yw01jvjQgXMMHhsOjUa/jc/7G5v8bjc8g2KCRlE//MMMJv5x4bHSSEf/zDOx7qe9zTxSRGo4YIpJ///zOrmGMTdiY/bnHUHo4SE3///f//8RQeUk4nbtmWfYkA4pV//M4xAsU+bKWXc8oAA2BvP3bN4ltfWLSRL3kzA5znc7xIVRjCimGSWQ6ut1O50/dTFGHYXDtyvX33b7fzINAEKAyhF9mIiq1Prtzw2idDVP/+s3gqCwAIb0lFaAMBxo9imIVY66gkesmb1Jr//M4xBYUio55nkGKlCOBduYkot6l4ZKs/qt12f01sWrrIAqCx6lb4w0qItHe9MpXEVVSs+b2mM5nR1vs6lMY6Puv1aY1F0FSFlU5v8A5FkCeWyFIfY6pNueqx9SrxciSnUXVWJZW1cRj0aeF//M4xCIUycJUCMvQGMQBosI9XdOl+391FjGilr5mohuxBNHnPquwy0q6hriv/46WpZVWUEYqgyV///////UqEbGAGQBohhy2rzzvNyfUUmZqwXZWNDYRTULoJ09m0OPZVenH3jrr07Kpb23p//M4xC0RyS5MDsJEWOqEEiVAUS7LPxYKAZiu//7djrMKNd6/9AT1VTdwYB2KChQDLNsPTBCt5w0udEpPI4uy0XPCYSsLmRUJu8oAcAUqVhfQwc807IsWDyqWrQ1VgEGeTFwmIj1tGprnrCah//M4xEQTQR4sANpGWO7/oV9/f///6AkwaKr5nYNratl02bS92YSA9LqNoYpgsJF1WUyYGUKl7JEIh532t3THZPSouBBZC2C6TsOj3fv7fmRTe5FX+upf7p/t11U2YpUqNPJICKJkwXyY+oAt//M4xFYSSK4oDOJSTCYqVjga3yoVWBOIgtYYYDs8VxpxaYPp1iXqyj4A6NSBMVA54YKOjR6YYy1xKzod7mO1J6Posv2XbNen/jXLW1ya37A3hcmkKmVhQNA1LAVx5BEq/IjXRL5X1ezlvU////M4xGsSgL4gANMQUM8j/rdT5XJZ34iqf/5aAng1xNBfkNH8PSMIWUXUdhBy8GscJpH6dx3HunFGMDopSbFqSk404UBmJjGTWwyNWsllllkssssBUMmQELivbiooLP///qFUmQkLitVMQU1F//M4xIALsB5AXnpEADMuMTAwVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV//M4xLATCSlsAHmGyFVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVVV\" type=\"audio/mpeg\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcxSztpxzh-t",
        "colab_type": "text"
      },
      "source": [
        "# Export Sklearn model: predict on Kaggle set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnLNHVtR6UQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = VotingClassifier(estimators=[\n",
        "                  ('lsvc', LinearSVC(C=0.15,dual=False)),\n",
        "                  ('mnb', MultinomialNB(alpha=0.25)),\n",
        "                  ('nn', MLPClassifier(**{'max_iter': 1, 'hidden_layer_sizes': (256,), 'batch_size': 64})),\n",
        "                ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swCBX9Pb0eiY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "1e3dee1c-bed3-4e6d-bc97-b5559f57c58e"
      },
      "source": [
        "clf.fit(X, y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "C:\\Users\\vap43\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('lsvc',\n",
              "                              LinearSVC(C=0.15, class_weight=None, dual=False,\n",
              "                                        fit_intercept=True, intercept_scaling=1,\n",
              "                                        loss='squared_hinge', max_iter=1000,\n",
              "                                        multi_class='ovr', penalty='l2',\n",
              "                                        random_state=None, tol=0.0001,\n",
              "                                        verbose=0)),\n",
              "                             ('mnb',\n",
              "                              MultinomialNB(alpha=0.25, class_prior=None,\n",
              "                                            fit_prior=True)),\n",
              "                             ('nn',\n",
              "                              MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                            batc...\n",
              "                                            beta_2=0.999, early_stopping=False,\n",
              "                                            epsilon=1e-08,\n",
              "                                            hidden_layer_sizes=(256,),\n",
              "                                            learning_rate='constant',\n",
              "                                            learning_rate_init=0.001,\n",
              "                                            max_iter=1, momentum=0.9,\n",
              "                                            n_iter_no_change=10,\n",
              "                                            nesterovs_momentum=True,\n",
              "                                            power_t=0.5, random_state=None,\n",
              "                                            shuffle=True, solver='adam',\n",
              "                                            tol=0.0001, validation_fraction=0.1,\n",
              "                                            verbose=False, warm_start=False))],\n",
              "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
              "                 weights=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tllvo_pW0utW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Kaggle_y_pred = clf.predict(Kaggle_Test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8W-NFV3A62qL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9e76636-c4ff-4496-8d38-3c9fd6068455"
      },
      "source": [
        "print(Kaggle_y_pred.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNKz92Wlzgbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_and_save_submission(predictions, file_name=\"submission.csv\"):\n",
        "    ids = [i for i in range(len(predictions))]\n",
        "    sub_df = pd.DataFrame(data=list(zip(ids, predictions)), columns=[\"Id\",\"Category\"])\n",
        "    sub_df.to_csv(file_name, index=False)\n",
        "\n",
        "create_and_save_submission(Kaggle_y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}