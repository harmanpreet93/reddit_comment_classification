{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "Rf6FdTF2fPbV",
    "outputId": "2b901c69-1b6b-4812-f788-2de1793e3bf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_gggPJfSTES"
   },
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "0rF3J7b3iINq",
    "outputId": "fd909c01-fdb5-4198-994b-b7996cb037f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# import random\n",
    "from nltk.corpus import stopwords\n",
    "# from nltk.stem import PorterStemmer\n",
    "from nltk import download\n",
    "# from collections import Counter\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# print(\"Downloading stop-words..\")\n",
    "download('stopwords') # nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwAo0kb6ScFd"
   },
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H2pYPwlZiMD5"
   },
   "outputs": [],
   "source": [
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    base_path = \"/content/drive/My Drive/ML_data/homework_4_kaggle/\"\n",
    "else:\n",
    "    base_path = \"\"\n",
    "\n",
    "TRAIN_DATA_PATH = base_path + \"data/data_train.pkl\"\n",
    "TEST_DATA_PATH = base_path + \"data/data_test.pkl\"\n",
    "\n",
    "\n",
    "train_data = pd.read_pickle(TRAIN_DATA_PATH)\n",
    "test_data  = pd.read_pickle(TEST_DATA_PATH)\n",
    "\n",
    "X      = np.array(train_data[0])\n",
    "y      = np.array(train_data[1])\n",
    "X_test = np.array(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GFPgtCFYShcr"
   },
   "source": [
    "##### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "evAeNC8qv8Yi"
   },
   "outputs": [],
   "source": [
    "# create csv in desired submission format\n",
    "def create_and_save_submission(predictions, file_name=\"submission.csv\"):\n",
    "    ids = [i for i in range(len(predictions))]\n",
    "    sub_df = pd.DataFrame(data=list(zip(ids, predictions)), columns=[\"Id\",\"Category\"])\n",
    "    sub_df.to_csv(file_name, index=False)\n",
    "    \n",
    "\n",
    "# evauate model score \n",
    "def evaluate_model(Model, X, y, kfold=True):\n",
    "    accuracy = []\n",
    "\n",
    "    if kfold:\n",
    "        print(\"Evaluating model performance using k-fold...\")\n",
    "        \n",
    "        kfold = KFold(\n",
    "            n_splits=5,\n",
    "            shuffle=True,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "\n",
    "        for train_index, test_index in kfold.split(X):\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "            Model.fit(X_train, y_train)\n",
    "            accuracy.append(Model.score(X_test, y_test))\n",
    "    \n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        Model.fit(X_train, y_train)\n",
    "        accuracy.append(Model.score(X_test, y_test))\n",
    "    \n",
    "    return np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dftxcp1hSkeo"
   },
   "source": [
    "##### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cV-GKoRO5BbP"
   },
   "outputs": [],
   "source": [
    "# classes = set(y)\n",
    "\n",
    "# encode y\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "vector_Y = label_encoder.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GKUCeUXBpg81",
    "outputId": "fa24e1d7-83e7-4e05-ac68-dbfc7e6a9e08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 73761), (70000, 73761))"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode X\n",
    "# vectorizer = CountVectorizer()\n",
    "vectorizer = TfidfVectorizer(stop_words='english',  sublinear_tf=True, ngram_range=(1,1), strip_accents='unicode')\n",
    "vectorizer.fit(X)\n",
    "vector_X = vectorizer.transform(X)\n",
    "vector_X_test = vectorizer.transform(X_test)\n",
    "\n",
    "vector_X_test.shape, vector_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yiF4rkt7Wq-h"
   },
   "outputs": [],
   "source": [
    "mnb_clf = MultinomialNB(alpha=0.25)\n",
    "brnb_clf = BernoulliNB(alpha=0.25)\n",
    "random_clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "decision_clf = DecisionTreeClassifier(max_depth=10)\n",
    "sgd_clf = SGDClassifier(max_iter=100, n_jobs=-1, loss='hinge')\n",
    "log_clf = SGDClassifier(loss='log', max_iter=100, n_jobs=-1)\n",
    "linear_svc = LinearSVC(loss='squared_hinge', dual=False, C=0.15, max_iter=100)\n",
    "adaboost_clf = AdaBoostClassifier(base_estimator=random_clf, n_estimators=10)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4dqpMPx5eKiW",
    "outputId": "0e058aab-9f76-4aaa-c995-952d0c51c469"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5696428571428571"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(linear_svc, vector_X, vector_Y, kfold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "EtNK_mv6aB32",
    "outputId": "ea40cd3c-170d-43c4-c7ed-9adc02f933e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.577"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# voting classifier\n",
    "baap_clf = VotingClassifier(estimators=[\n",
    "                                        ('clf1', mnb_clf), \n",
    "                                        ('clf2', brnb_clf), \n",
    "                                        ('clf3', linear_svc), \n",
    "                                        ('clf4', sgd_clf)\n",
    "                                        ],\n",
    "                            voting='hard')\n",
    "\n",
    "\n",
    "evaluate_model(baap_clf, vector_X, vector_Y, kfold=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tGgpm4wWdjZB"
   },
   "source": [
    "##### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_s5DCCT2a5b6"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GLPDCHl1dde2"
   },
   "outputs": [],
   "source": [
    "# confusion_ma/trix(evaluate_model(model, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7AxCsjP_iuxP"
   },
   "source": [
    "### Create Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F6SJf-5zqhrw"
   },
   "outputs": [],
   "source": [
    "predictions = list(label_encoder.inverse_transform(model.predict(vector_X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FpLMwWoIqaCI"
   },
   "outputs": [],
   "source": [
    "create_and_save_submission(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3TvSa8NvSUo_"
   },
   "source": [
    "### Word2Vec Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KihM-CjpSmOy"
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q6-D4eQWV5r-"
   },
   "outputs": [],
   "source": [
    "stop_words_list = stopwords.words('english')\n",
    "# stemmer = PorterStemmer()\n",
    "\n",
    "pattern = re.compile(r'\\b\\w\\w+\\b')\n",
    "processed_X = []\n",
    "for sentence in X:\n",
    "    processed_X.append([word.lower() if word.lower() not in stop_words_list else \"stop_word\" for word in re.findall(pattern, sentence.lower())])\n",
    "    # processed_X.append([stemmer.stem(word) for word in re.findall(pattern, sentence.lower()) if word not in stop_words_list])\n",
    "processed_X = np.asarray(processed_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UROhjRtY4aSC"
   },
   "source": [
    "### Train word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CIxzGMZh9Rel",
    "outputId": "231d9a8e-cd64-4fe5-e0e4-4082150f0e94"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-11-06 20:05:28,631 : INFO : collecting all words and their counts\n",
      "2019-11-06 20:05:28,633 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-11-06 20:05:28,702 : INFO : PROGRESS: at sentence #10000, processed 403827 words, keeping 26591 word types\n",
      "2019-11-06 20:05:28,781 : INFO : PROGRESS: at sentence #20000, processed 819912 words, keeping 38534 word types\n",
      "2019-11-06 20:05:28,862 : INFO : PROGRESS: at sentence #30000, processed 1228962 words, keeping 47672 word types\n",
      "2019-11-06 20:05:28,951 : INFO : PROGRESS: at sentence #40000, processed 1649577 words, keeping 55532 word types\n",
      "2019-11-06 20:05:29,036 : INFO : PROGRESS: at sentence #50000, processed 2067376 words, keeping 62160 word types\n",
      "2019-11-06 20:05:29,121 : INFO : PROGRESS: at sentence #60000, processed 2477292 words, keeping 68514 word types\n",
      "2019-11-06 20:05:29,205 : INFO : collected 74121 word types from a corpus of 2884251 raw words and 70000 sentences\n",
      "2019-11-06 20:05:29,206 : INFO : Loading a fresh vocabulary\n",
      "2019-11-06 20:05:29,333 : INFO : effective_min_count=1 retains 74121 unique words (100% of original 74121, drops 0)\n",
      "2019-11-06 20:05:29,334 : INFO : effective_min_count=1 leaves 2884251 word corpus (100% of original 2884251, drops 0)\n",
      "2019-11-06 20:05:29,560 : INFO : deleting the raw counts dictionary of 74121 items\n",
      "2019-11-06 20:05:29,563 : INFO : sample=0 downsamples 0 most-common words\n",
      "2019-11-06 20:05:29,564 : INFO : downsampling leaves estimated 2884251 word corpus (100.0% of prior 2884251)\n",
      "2019-11-06 20:05:29,835 : INFO : estimated required memory for 74121 words and 100 dimensions: 96357300 bytes\n",
      "2019-11-06 20:05:29,836 : INFO : resetting layer weights\n",
      "2019-11-06 20:05:43,516 : INFO : training model with 8 workers on 74121 vocabulary and 100 features, using sg=0 hs=0 sample=0 negative=5 window=5\n",
      "2019-11-06 20:05:44,527 : INFO : EPOCH 1 - PROGRESS: at 51.23% examples, 1475064 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:05:45,373 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:05:45,382 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:05:45,389 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:05:45,392 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:05:45,396 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:05:45,399 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:05:45,400 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:05:45,404 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:05:45,405 : INFO : EPOCH - 1 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1534379 effective words/s\n",
      "2019-11-06 20:05:46,416 : INFO : EPOCH 2 - PROGRESS: at 49.93% examples, 1433580 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:05:47,275 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:05:47,288 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:05:47,293 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:05:47,295 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:05:47,300 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:05:47,302 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:05:47,303 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:05:47,307 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:05:47,308 : INFO : EPOCH - 2 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1522196 effective words/s\n",
      "2019-11-06 20:05:48,319 : INFO : EPOCH 3 - PROGRESS: at 52.30% examples, 1503553 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:05:49,144 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:05:49,150 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:05:49,155 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:05:49,159 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:05:49,172 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:05:49,173 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:05:49,174 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:05:49,175 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:05:49,176 : INFO : EPOCH - 3 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1551283 effective words/s\n",
      "2019-11-06 20:05:50,188 : INFO : EPOCH 4 - PROGRESS: at 49.93% examples, 1431107 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-06 20:05:51,080 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:05:51,087 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:05:51,091 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:05:51,095 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:05:51,101 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:05:51,104 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:05:51,106 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:05:51,108 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:05:51,108 : INFO : EPOCH - 4 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1498138 effective words/s\n",
      "2019-11-06 20:05:52,120 : INFO : EPOCH 5 - PROGRESS: at 53.40% examples, 1531681 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:05:52,937 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:05:52,943 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:05:52,949 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:05:52,952 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:05:52,956 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:05:52,962 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:05:52,963 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:05:52,966 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:05:52,967 : INFO : EPOCH - 5 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1558726 effective words/s\n",
      "2019-11-06 20:05:53,979 : INFO : EPOCH 6 - PROGRESS: at 52.68% examples, 1510452 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:05:54,787 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:05:54,801 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:05:54,805 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:05:54,809 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:05:54,811 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:05:54,814 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:05:54,815 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:05:54,819 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:05:54,820 : INFO : EPOCH - 6 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1563208 effective words/s\n",
      "2019-11-06 20:05:55,833 : INFO : EPOCH 7 - PROGRESS: at 53.00% examples, 1519811 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:05:56,626 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:05:56,637 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:05:56,642 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:05:56,643 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:05:56,650 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:05:56,652 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:05:56,653 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:05:56,656 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:05:56,656 : INFO : EPOCH - 7 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1577521 effective words/s\n",
      "2019-11-06 20:05:57,668 : INFO : EPOCH 8 - PROGRESS: at 53.40% examples, 1530558 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:05:58,462 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:05:58,468 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:05:58,472 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:05:58,475 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:05:58,479 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:05:58,485 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:05:58,487 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:05:58,491 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:05:58,492 : INFO : EPOCH - 8 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1577943 effective words/s\n",
      "2019-11-06 20:05:59,501 : INFO : EPOCH 9 - PROGRESS: at 54.36% examples, 1564741 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:00,294 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:00,299 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:00,305 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:00,308 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:00,317 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:00,319 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:00,320 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:00,323 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:00,324 : INFO : EPOCH - 9 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1581091 effective words/s\n",
      "2019-11-06 20:06:01,335 : INFO : EPOCH 10 - PROGRESS: at 53.40% examples, 1531846 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:02,131 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:02,143 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:02,147 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:02,151 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:02,154 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:02,158 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:02,160 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:02,162 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:02,162 : INFO : EPOCH - 10 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1575717 effective words/s\n",
      "2019-11-06 20:06:03,176 : INFO : EPOCH 11 - PROGRESS: at 53.40% examples, 1528308 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:03,999 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:04,005 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:04,010 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:04,013 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:04,017 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:04,020 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:04,024 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:04,028 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:04,029 : INFO : EPOCH - 11 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1552046 effective words/s\n",
      "2019-11-06 20:06:05,041 : INFO : EPOCH 12 - PROGRESS: at 53.67% examples, 1539920 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:05,833 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:05,842 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:05,846 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:05,849 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:05,854 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:05,859 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:05,860 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:05,863 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:05,864 : INFO : EPOCH - 12 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1578483 effective words/s\n",
      "2019-11-06 20:06:06,874 : INFO : EPOCH 13 - PROGRESS: at 54.05% examples, 1553903 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:07,660 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:07,667 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:07,676 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:07,680 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:07,682 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:07,686 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:07,688 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:07,692 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:07,693 : INFO : EPOCH - 13 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1583678 effective words/s\n",
      "2019-11-06 20:06:08,704 : INFO : EPOCH 14 - PROGRESS: at 54.65% examples, 1571149 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:09,477 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:09,488 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:09,493 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:09,496 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:09,500 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:09,502 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:09,503 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:09,505 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:09,506 : INFO : EPOCH - 14 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1597580 effective words/s\n",
      "2019-11-06 20:06:10,521 : INFO : EPOCH 15 - PROGRESS: at 54.05% examples, 1546648 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:11,296 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:11,305 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:11,313 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:11,317 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:11,323 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:11,324 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:11,325 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:11,328 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:11,329 : INFO : EPOCH - 15 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1589245 effective words/s\n",
      "2019-11-06 20:06:12,338 : INFO : EPOCH 16 - PROGRESS: at 53.40% examples, 1535391 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:13,120 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:13,127 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:13,131 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:13,135 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:13,139 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:13,141 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:13,144 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:13,148 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:13,149 : INFO : EPOCH - 16 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1591454 effective words/s\n",
      "2019-11-06 20:06:14,160 : INFO : EPOCH 17 - PROGRESS: at 54.05% examples, 1551356 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:14,941 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:14,954 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:14,958 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:14,961 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:14,966 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:14,967 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:14,969 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:14,971 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:14,972 : INFO : EPOCH - 17 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1589053 effective words/s\n",
      "2019-11-06 20:06:15,981 : INFO : EPOCH 18 - PROGRESS: at 54.36% examples, 1563979 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:16,748 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:16,753 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:16,761 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:16,765 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:16,769 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:16,773 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:16,774 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:16,777 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:16,778 : INFO : EPOCH - 18 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1604126 effective words/s\n",
      "2019-11-06 20:06:17,789 : INFO : EPOCH 19 - PROGRESS: at 51.93% examples, 1491558 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-06 20:06:18,585 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:18,601 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:18,607 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:18,611 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:18,615 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:18,616 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:18,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:18,621 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:18,622 : INFO : EPOCH - 19 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1570304 effective words/s\n",
      "2019-11-06 20:06:19,631 : INFO : EPOCH 20 - PROGRESS: at 51.93% examples, 1496699 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-06 20:06:20,470 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:20,474 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:20,478 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:20,485 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:20,486 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:20,494 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:20,496 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:20,498 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:20,499 : INFO : EPOCH - 20 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1543332 effective words/s\n",
      "2019-11-06 20:06:21,513 : INFO : EPOCH 21 - PROGRESS: at 51.63% examples, 1478474 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:22,333 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:22,338 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:22,346 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:22,349 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:22,353 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:22,356 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:22,357 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:22,360 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:22,361 : INFO : EPOCH - 21 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1555402 effective words/s\n",
      "2019-11-06 20:06:23,373 : INFO : EPOCH 22 - PROGRESS: at 53.40% examples, 1531088 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:24,190 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:24,194 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:24,199 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:24,204 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:24,213 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:24,215 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:24,216 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:24,218 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:24,219 : INFO : EPOCH - 22 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1558888 effective words/s\n",
      "2019-11-06 20:06:25,228 : INFO : EPOCH 23 - PROGRESS: at 54.36% examples, 1564385 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:25,989 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:25,998 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:26,006 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:26,009 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:26,013 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:26,015 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:26,016 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:26,019 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:26,020 : INFO : EPOCH - 23 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1608711 effective words/s\n",
      "2019-11-06 20:06:27,036 : INFO : EPOCH 24 - PROGRESS: at 51.93% examples, 1484229 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:27,887 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:27,892 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:27,897 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:27,901 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:27,906 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:27,910 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:27,911 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:27,915 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:27,916 : INFO : EPOCH - 24 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1527136 effective words/s\n",
      "2019-11-06 20:06:28,928 : INFO : EPOCH 25 - PROGRESS: at 50.60% examples, 1451639 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-06 20:06:29,780 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:29,785 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:29,790 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:29,793 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:29,804 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:29,805 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:29,806 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:29,809 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:29,810 : INFO : EPOCH - 25 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1529551 effective words/s\n",
      "2019-11-06 20:06:30,818 : INFO : EPOCH 26 - PROGRESS: at 53.00% examples, 1525893 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:31,692 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:31,700 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:31,707 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:31,708 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:31,713 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:31,722 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:31,723 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:31,726 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:31,727 : INFO : EPOCH - 26 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1510181 effective words/s\n",
      "2019-11-06 20:06:32,736 : INFO : EPOCH 27 - PROGRESS: at 48.27% examples, 1386327 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:33,660 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:33,661 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:33,669 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:33,671 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:33,680 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:33,683 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:33,684 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:33,685 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:33,686 : INFO : EPOCH - 27 : training on 2884251 raw words (2884251 effective words) took 2.0s, 1478603 effective words/s\n",
      "2019-11-06 20:06:34,701 : INFO : EPOCH 28 - PROGRESS: at 52.68% examples, 1506640 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:35,541 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:35,546 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:35,553 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:35,558 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:35,560 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:35,567 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:35,569 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:35,570 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:35,571 : INFO : EPOCH - 28 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1536653 effective words/s\n",
      "2019-11-06 20:06:36,582 : INFO : EPOCH 29 - PROGRESS: at 52.30% examples, 1502021 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:37,391 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:37,398 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:37,403 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:37,408 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:37,413 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:37,419 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:37,420 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:37,423 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:37,424 : INFO : EPOCH - 29 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1563390 effective words/s\n",
      "2019-11-06 20:06:38,433 : INFO : EPOCH 30 - PROGRESS: at 52.68% examples, 1513841 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:39,233 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:39,238 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:39,242 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:39,245 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:39,251 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:39,255 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:39,257 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:39,261 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:39,262 : INFO : EPOCH - 30 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1575678 effective words/s\n",
      "2019-11-06 20:06:40,286 : INFO : EPOCH 31 - PROGRESS: at 52.30% examples, 1482857 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:41,094 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:41,101 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:41,107 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:41,110 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:41,113 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:41,119 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:41,121 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:41,122 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:41,124 : INFO : EPOCH - 31 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1555529 effective words/s\n",
      "2019-11-06 20:06:42,133 : INFO : EPOCH 32 - PROGRESS: at 52.68% examples, 1515034 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:42,964 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:42,970 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:42,976 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:42,982 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:42,986 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:42,987 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:42,989 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:42,992 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:42,993 : INFO : EPOCH - 32 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1549757 effective words/s\n",
      "2019-11-06 20:06:44,003 : INFO : EPOCH 33 - PROGRESS: at 53.40% examples, 1533393 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:44,808 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:44,818 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:44,822 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:44,826 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:44,832 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:44,838 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:44,842 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:44,844 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:44,845 : INFO : EPOCH - 33 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1564272 effective words/s\n",
      "2019-11-06 20:06:45,854 : INFO : EPOCH 34 - PROGRESS: at 53.00% examples, 1524966 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:46,663 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:46,668 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:46,669 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:46,675 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:46,686 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:46,690 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:46,691 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:46,693 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:46,694 : INFO : EPOCH - 34 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1566426 effective words/s\n",
      "2019-11-06 20:06:47,704 : INFO : EPOCH 35 - PROGRESS: at 53.40% examples, 1533470 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:48,520 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:48,527 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:48,531 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:48,534 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:48,542 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:48,545 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:48,548 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:48,550 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:48,551 : INFO : EPOCH - 35 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1559970 effective words/s\n",
      "2019-11-06 20:06:49,567 : INFO : EPOCH 36 - PROGRESS: at 51.63% examples, 1474472 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:50,493 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:50,503 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:50,507 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:50,515 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:50,518 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:50,520 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:50,522 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:50,524 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:50,525 : INFO : EPOCH - 36 : training on 2884251 raw words (2884251 effective words) took 2.0s, 1466423 effective words/s\n",
      "2019-11-06 20:06:51,537 : INFO : EPOCH 37 - PROGRESS: at 54.05% examples, 1550204 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:52,350 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:52,357 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:52,360 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:52,362 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:52,367 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:52,370 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:52,373 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:52,377 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:52,378 : INFO : EPOCH - 37 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1563001 effective words/s\n",
      "2019-11-06 20:06:53,389 : INFO : EPOCH 38 - PROGRESS: at 52.30% examples, 1503368 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:54,205 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:54,210 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:54,217 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:54,223 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:54,228 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:54,231 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:54,232 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:54,236 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:54,237 : INFO : EPOCH - 38 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1558315 effective words/s\n",
      "2019-11-06 20:06:55,246 : INFO : EPOCH 39 - PROGRESS: at 52.68% examples, 1514992 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:56,098 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:56,101 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:56,110 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:56,117 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:56,120 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:56,122 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:56,124 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:56,126 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:56,127 : INFO : EPOCH - 39 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1532400 effective words/s\n",
      "2019-11-06 20:06:57,136 : INFO : EPOCH 40 - PROGRESS: at 51.93% examples, 1495207 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:57,955 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:57,959 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:57,966 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:57,970 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:57,973 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:57,981 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:57,982 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:57,984 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:57,985 : INFO : EPOCH - 40 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1558860 effective words/s\n",
      "2019-11-06 20:06:58,995 : INFO : EPOCH 41 - PROGRESS: at 52.30% examples, 1504747 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:06:59,833 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:06:59,837 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:06:59,842 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:06:59,849 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:06:59,852 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:06:59,856 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:06:59,858 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:06:59,863 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:06:59,864 : INFO : EPOCH - 41 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1542053 effective words/s\n",
      "2019-11-06 20:07:00,872 : INFO : EPOCH 42 - PROGRESS: at 53.00% examples, 1525815 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:07:01,693 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:07:01,698 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:07:01,702 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:07:01,705 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:07:01,711 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:07:01,713 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:07:01,715 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:07:01,719 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:07:01,720 : INFO : EPOCH - 42 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1560206 effective words/s\n",
      "2019-11-06 20:07:02,729 : INFO : EPOCH 43 - PROGRESS: at 53.67% examples, 1544507 words/s, in_qsize 14, out_qsize 1\n",
      "2019-11-06 20:07:03,542 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:07:03,548 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:07:03,555 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:07:03,560 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:07:03,563 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:07:03,567 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:07:03,568 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:07:03,571 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:07:03,572 : INFO : EPOCH - 43 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1563444 effective words/s\n",
      "2019-11-06 20:07:04,583 : INFO : EPOCH 44 - PROGRESS: at 51.93% examples, 1493623 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:07:05,442 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:07:05,449 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:07:05,461 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:07:05,465 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:07:05,468 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:07:05,470 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:07:05,471 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:07:05,474 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:07:05,475 : INFO : EPOCH - 44 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1521872 effective words/s\n",
      "2019-11-06 20:07:06,485 : INFO : EPOCH 45 - PROGRESS: at 53.40% examples, 1535442 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-06 20:07:07,301 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:07:07,307 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:07:07,311 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:07:07,314 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:07:07,318 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:07:07,325 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:07:07,327 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:07:07,329 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:07:07,330 : INFO : EPOCH - 45 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1562326 effective words/s\n",
      "2019-11-06 20:07:08,344 : INFO : EPOCH 46 - PROGRESS: at 51.93% examples, 1488185 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:07:09,173 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:07:09,176 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:07:09,184 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:07:09,189 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:07:09,195 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:07:09,196 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:07:09,198 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:07:09,203 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:07:09,204 : INFO : EPOCH - 46 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1545497 effective words/s\n",
      "2019-11-06 20:07:10,215 : INFO : EPOCH 47 - PROGRESS: at 53.67% examples, 1542718 words/s, in_qsize 16, out_qsize 1\n",
      "2019-11-06 20:07:10,991 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:07:10,997 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:07:11,002 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:07:11,004 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:07:11,012 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:07:11,014 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:07:11,016 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:07:11,021 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:07:11,022 : INFO : EPOCH - 47 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1593646 effective words/s\n",
      "2019-11-06 20:07:12,042 : INFO : EPOCH 48 - PROGRESS: at 54.65% examples, 1558042 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:07:12,840 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:07:12,850 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:07:12,855 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:07:12,857 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:07:12,865 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:07:12,868 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:07:12,869 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:07:12,871 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:07:12,871 : INFO : EPOCH - 48 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1566307 effective words/s\n",
      "2019-11-06 20:07:13,881 : INFO : EPOCH 49 - PROGRESS: at 53.67% examples, 1544251 words/s, in_qsize 16, out_qsize 0\n",
      "2019-11-06 20:07:14,688 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:07:14,695 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:07:14,704 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:07:14,708 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:07:14,712 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:07:14,713 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:07:14,715 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:07:14,717 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:07:14,718 : INFO : EPOCH - 49 : training on 2884251 raw words (2884251 effective words) took 1.8s, 1568736 effective words/s\n",
      "2019-11-06 20:07:15,729 : INFO : EPOCH 50 - PROGRESS: at 52.30% examples, 1501906 words/s, in_qsize 15, out_qsize 0\n",
      "2019-11-06 20:07:16,553 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2019-11-06 20:07:16,560 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2019-11-06 20:07:16,565 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2019-11-06 20:07:16,568 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2019-11-06 20:07:16,572 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2019-11-06 20:07:16,577 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2019-11-06 20:07:16,579 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2019-11-06 20:07:16,581 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2019-11-06 20:07:16,582 : INFO : EPOCH - 50 : training on 2884251 raw words (2884251 effective words) took 1.9s, 1553833 effective words/s\n",
      "2019-11-06 20:07:16,582 : INFO : training on a 144212550 raw words (144212550 effective words) took 93.1s, 1549586 effective words/s\n"
     ]
    }
   ],
   "source": [
    "w2v_model = Word2Vec(processed_X, size=100, window=5, min_count=1, workers=8, iter=50, sample=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgMOjprM4ePm"
   },
   "source": [
    "### Test word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TGA7oofVPC23"
   },
   "source": [
    "##### Mean w2v Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iwrqrop1xIDP"
   },
   "outputs": [],
   "source": [
    "class MeanEmbeddingVectorizer():\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec.wv\n",
    "        # if text is empty or no word found in the word2vec vocab - return vector of zeros\n",
    "        self.dim = self.word2vec.vector_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # returns avg embedded vector for each X\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0) \n",
    "            for words in X\n",
    "        ])\n",
    "\n",
    "\n",
    "# def avg_feature_vector(words, model, num_features=100):\n",
    "#     feature_vec = np.zeros((num_features, ), dtype='float32')\n",
    "#     n_words = 0\n",
    "#     vocab = model.wv.vocab\n",
    "#     for word in words:\n",
    "#         if word in vocab:\n",
    "#             n_words += 1\n",
    "#             feature_vec = np.add(feature_vec, model.wv[word])\n",
    "#     if (n_words > 0):\n",
    "#         feature_vec = np.divide(feature_vec, n_words)\n",
    "#     return feature_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q3py1zUOPNou"
   },
   "source": [
    "##### Tfidf w2v Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vN82CUR8w6yU"
   },
   "outputs": [],
   "source": [
    "class TfidfEmbeddingVectorizer():\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec.wv\n",
    "        self.word2weight = None\n",
    "        self.dim = self.word2vec.vector_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(stop_words='english', sublinear_tf=True, analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf,\n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # return weighted vecotr using tfidf\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w] for w in words if w in self.word2vec] or [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HbezPjc6hy1X"
   },
   "source": [
    "### Blog\n",
    "[link](https://github.com/nadbordrozd/blog_stuff/blob/master/classification_w2v/benchmarking_python3.ipynb)\n",
    "\n",
    "[blog](http://nadbordrozd.github.io/blog/2016/05/20/text-classification-with-word2vec/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y-9o_LrRy_IC"
   },
   "outputs": [],
   "source": [
    "# start with naive bayes of the multinomial and bernoulli \n",
    "# with either pure counts or tfidf features\n",
    "mult_nb = Pipeline([\n",
    "                    (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), \n",
    "                    (\"multinomial nb\", MultinomialNB(alpha=0.25))])\n",
    "bern_nb = Pipeline([\n",
    "                    (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), \n",
    "                    (\"bernoulli nb\", BernoulliNB(alpha=0.25))])\n",
    "mult_nb_tfidf = Pipeline([\n",
    "                          (\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), \n",
    "                          (\"multinomial nb\", MultinomialNB(alpha=0.25))])\n",
    "bern_nb_tfidf = Pipeline([\n",
    "                          (\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), \n",
    "                          (\"bernoulli nb\", BernoulliNB(alpha=0.25))])\n",
    "svc = Pipeline([\n",
    "                (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)), \n",
    "                (\"linear svc\", SVC(kernel=\"linear\"))])\n",
    "svc_tfidf = Pipeline([\n",
    "                      (\"tfidf_vectorizer\", TfidfVectorizer(analyzer=lambda x: x)), \n",
    "                      (\"linear svc\", SVC(kernel=\"linear\", C=0.15))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k1m9Qe0Qw_0m"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "etree_w2v = Pipeline([\n",
    "    (\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v_model)),\n",
    "    (\"extra trees\", ExtraTreesClassifier(n_estimators=100))])\n",
    "\n",
    "etree_w2v_tfidf = Pipeline([\n",
    "    (\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v_model)),\n",
    "    (\"extra trees\", ExtraTreesClassifier(n_estimators=100))])\n",
    "\n",
    "multi_nb_w2v_tfidf = Pipeline([\n",
    "    (\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v_model)),\n",
    "    (\"multinomial nb\", MultinomialNB(alpha=0.25))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "du02RCXrYkDD",
    "outputId": "4cb71452-f9a3-447b-e879-07b25542a556"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model performance using k-fold...\n",
      "Evaluating model performance using k-fold...\n",
      "Evaluating model performance using k-fold...\n",
      "Evaluating model performance using k-fold...\n",
      "Evaluating model performance using k-fold...\n",
      "Evaluating model performance using k-fold...\n",
      "model            score\n",
      "-------------  -------\n",
      "mult_nb_tfidf   0.5710\n",
      "mult_nb         0.5571\n",
      "bern_nb         0.5163\n",
      "bern_nb_tfidf   0.5163\n",
      "w2v_tfidf       0.3944\n",
      "w2v             0.3608\n"
     ]
    }
   ],
   "source": [
    "all_models = [\n",
    "    (\"mult_nb\", mult_nb),\n",
    "    (\"mult_nb_tfidf\", mult_nb_tfidf),\n",
    "    (\"bern_nb\", bern_nb),\n",
    "    (\"bern_nb_tfidf\", bern_nb_tfidf),\n",
    "    # (\"svc\", svc), # takes too long\n",
    "    # (\"svc_tfidf\", svc_tfidf),\n",
    "    (\"w2v\", etree_w2v),\n",
    "    (\"w2v_tfidf\", etree_w2v_tfidf),\n",
    "]\n",
    "\n",
    "unsorted_scores = [(name, evaluate_model(model, processed_X, vector_Y, kfold=True)) for name, model in all_models]\n",
    "scores = sorted(unsorted_scores, key=lambda x: -x[1])\n",
    "\n",
    "from tabulate import tabulate\n",
    "%matplotlib inline\n",
    "\n",
    "print (tabulate(scores, floatfmt=\".4f\", headers=(\"model\", 'score')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "02RcszD2Y-eH"
   },
   "outputs": [],
   "source": [
    "w2v_X = []\n",
    "for x in processed_X:\n",
    "    w2v_X.append(avg_feature_vector(x, w2v_model))\n",
    "\n",
    "w2v_X = np.asarray(w2v_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wTCy_zpkA-9"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(w2v_X, vector_Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6IOJCG2RkwjT"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5nRWEZZEZA20",
    "outputId": "c7011467-e706-4855-a37c-994ad09d6203"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.29864\n"
     ]
    }
   ],
   "source": [
    "# model = MultinomialNB()\n",
    "model = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "# model = LinearSVC(random_state=0, tol=1e-5, C=1.0)\n",
    "# print(\"Evaluation Accuracy: %0.5f\"%evaluate_model(model, w2v_X, vector_Y))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Training Accuracy: %0.5f\"%model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hzPnzEHmZ8Ig",
    "outputId": "da730088-5adb-4e8a-e41f-d48465116e6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.19386\n"
     ]
    }
   ],
   "source": [
    "# model = MultinomialNB()\n",
    "model = DecisionTreeClassifier()\n",
    "# model = LinearSVC(random_state=0, tol=1e-5, C=1.0)\n",
    "# print(\"Evaluation Accuracy: %0.5f\"%evaluate_model(model, w2v_X, vector_Y))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: %0.5f\"%model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "A2OmZwGdm3Bw",
    "outputId": "26bc8a26-a3f0-4996-e2a9-dcd2be87834f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34036\n"
     ]
    }
   ],
   "source": [
    "model = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Accuracy: %0.5f\"%model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "an6jtt15lDNp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [
    "Y_gggPJfSTES",
    "GFPgtCFYShcr",
    "tGgpm4wWdjZB",
    "7AxCsjP_iuxP",
    "UROhjRtY4aSC",
    "TGA7oofVPC23",
    "Q3py1zUOPNou"
   ],
   "machine_shape": "hm",
   "name": "reddit_kaggle_prototyping.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
