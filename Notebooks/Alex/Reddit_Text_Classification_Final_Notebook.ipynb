{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reddit Text Classification Final Draft 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34rVf9SGL--I",
        "colab_type": "text"
      },
      "source": [
        "# Initialize globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5jf1ksbhM1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "project_path = 'C:/Users/vap43/Documents/GitHub/reddit_comment_classification/'\n",
        "TRAIN_DATA_PATH = project_path + \"data/data_train.pkl\"\n",
        "TEST_DATA_PATH = project_path + \"data/data_test.pkl\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5VRVSw0h5pP",
        "colab_type": "text"
      },
      "source": [
        "# Import the text and classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3EFl9T-igp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "train_data = pd.read_pickle(TRAIN_DATA_PATH)\n",
        "test_data  = pd.read_pickle(TEST_DATA_PATH)\n",
        "\n",
        "nb_X_Train = len(train_data[0])\n",
        "All_X = np.concatenate((np.array(train_data[0]),np.array(test_data)))\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "y = le.fit_transform(np.array(train_data[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewlSnlMdpM3a",
        "colab_type": "text"
      },
      "source": [
        "# Pre-process the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01kZ5H8ov2SI",
        "colab_type": "text"
      },
      "source": [
        "Remove stop words and stem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T9JISjh_QpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words_list = stopwords.words('english')\n",
        "pattern = re.compile(r'\\b\\w\\w+\\b')\n",
        "word_count = np.zeros(All_X.shape[0])\n",
        "\n",
        "for idx, sentence in enumerate(All_X):\n",
        "  All_X[idx] = \" \".join([word for word in re.findall(pattern, sentence.lower()) if word not in stop_words_list])\n",
        "  word_count[idx] = len(All_X[idx])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cbjQsTkvxjy",
        "colab_type": "text"
      },
      "source": [
        "Count and weight the terms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIoo9U7-vP_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_transformer = TfidfVectorizer(\n",
        "  ngram_range=(1, 1),\n",
        "  min_df=2,\n",
        "  strip_accents = \"unicode\",\n",
        "  sublinear_tf = True\n",
        ")\n",
        "All_X_ifidf = tfidf_transformer.fit_transform(All_X)\n",
        "\n",
        "X = All_X_ifidf[:nb_X_Train,:]\n",
        "Kaggle_Test_X = All_X_ifidf[nb_X_Train:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktTAloerSWy-",
        "colab_type": "text"
      },
      "source": [
        "# Train the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnLNHVtR6UQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "clf_vote =   VotingClassifier(\n",
        "  estimators=[\n",
        "    ('sgd',SGDClassifier(**{'penalty': 'l2', 'loss': 'modified_huber', 'class_weight': 'balanced', 'alpha': 0.0001})),\n",
        "    ('mnb', MultinomialNB(alpha=0.25)),\n",
        "    ('nn', MLPClassifier(**{'max_iter': 1, 'hidden_layer_sizes': (256,), 'batch_size': 64})),\n",
        "  ],\n",
        "  voting='soft',\n",
        "  weights=[1,1,1],\n",
        "  n_jobs=-1\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swCBX9Pb0eiY",
        "colab_type": "code",
        "outputId": "f86cdae7-b8fa-461a-b923-ac968d1dfd5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        }
      },
      "source": [
        "clf_vote.fit(X, y)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('sgd',\n",
              "                              SGDClassifier(alpha=0.0001, average=False,\n",
              "                                            class_weight='balanced',\n",
              "                                            early_stopping=False, epsilon=0.1,\n",
              "                                            eta0=0.0, fit_intercept=True,\n",
              "                                            l1_ratio=0.15,\n",
              "                                            learning_rate='optimal',\n",
              "                                            loss='modified_huber',\n",
              "                                            max_iter=1000, n_iter_no_change=5,\n",
              "                                            n_jobs=None, penalty='l2',\n",
              "                                            power_t=0.5, random_state=None,\n",
              "                                            shuffle=True, tol=0.001,\n",
              "                                            validation_fracti...\n",
              "                                            beta_2=0.999, early_stopping=False,\n",
              "                                            epsilon=1e-08,\n",
              "                                            hidden_layer_sizes=(256,),\n",
              "                                            learning_rate='constant',\n",
              "                                            learning_rate_init=0.001,\n",
              "                                            max_iter=1, momentum=0.9,\n",
              "                                            n_iter_no_change=10,\n",
              "                                            nesterovs_momentum=True,\n",
              "                                            power_t=0.5, random_state=None,\n",
              "                                            shuffle=True, solver='adam',\n",
              "                                            tol=0.0001, validation_fraction=0.1,\n",
              "                                            verbose=False, warm_start=False))],\n",
              "                 flatten_transform=True, n_jobs=-1, voting='soft',\n",
              "                 weights=[1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcxSztpxzh-t",
        "colab_type": "text"
      },
      "source": [
        "# Predict on Kaggle set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tllvo_pW0utW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Kaggle_y_pred = clf_vote.predict(Kaggle_Test_X)\n",
        "Kaggle_y_pred = le.inverse_transform(Kaggle_y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNKz92Wlzgbw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ids = [i for i in range(len(Kaggle_y_pred))]\n",
        "sub_df = pd.DataFrame(data=list(zip(ids, Kaggle_y_pred)), columns=[\"Id\",\"Category\"])\n",
        "sub_df.to_csv(\"submission.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}