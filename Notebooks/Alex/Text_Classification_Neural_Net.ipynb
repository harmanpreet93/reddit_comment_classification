{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification Neural Net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34rVf9SGL--I",
        "colab_type": "text"
      },
      "source": [
        "# Initialize globals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5jf1ksbhM1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os, glob, re\n",
        "\n",
        "project_path = 'C:/Users/vap43/Documents/GitHub/reddit_comment_classification/'\n",
        "TRAIN_DATA_PATH = project_path + \"data/data_train.pkl\"\n",
        "TEST_DATA_PATH = project_path + \"data/data_test.pkl\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5VRVSw0h5pP",
        "colab_type": "text"
      },
      "source": [
        "# Import the text and classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3EFl9T-igp8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_pickle(TRAIN_DATA_PATH)\n",
        "test_data  = pd.read_pickle(TEST_DATA_PATH)\n",
        "\n",
        "nb_X_Train = len(train_data[0])\n",
        "All_X = np.concatenate((np.array(train_data[0]),np.array(test_data)))\n",
        "y = np.array(train_data[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewlSnlMdpM3a",
        "colab_type": "text"
      },
      "source": [
        "# Pre-process the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01kZ5H8ov2SI",
        "colab_type": "text"
      },
      "source": [
        "Remove stop words and stem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T9JISjh_QpX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "stop_words_list = stopwords.words('english')\n",
        "pattern = re.compile(r'\\b\\w\\w+\\b')\n",
        "\n",
        "for idx, sentence in enumerate(All_X):\n",
        "  All_X[idx] = \" \".join([stemmer.stem(word) for word in re.findall(pattern, sentence.lower()) if word not in stop_words_list])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_YrdTYfvywF",
        "colab_type": "text"
      },
      "source": [
        "Count the terms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT-js4KyvObo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "  ngram_range=(1, 1),\n",
        "  min_df=2,\n",
        "  max_df=1.0,\n",
        "  max_features=None,\n",
        ")\n",
        "All_X_Counts = vectorizer.fit_transform(All_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cbjQsTkvxjy",
        "colab_type": "text"
      },
      "source": [
        "Weight the terms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIoo9U7-vP_N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "All_X_ifidf = tfidf_transformer.fit_transform(All_X_Counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-uaKq8IM4j0",
        "colab_type": "text"
      },
      "source": [
        "Split out the Train/test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fecyI4aCuslL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = All_X_ifidf[:nb_X_Train,:]\n",
        "Kaggle_Test_X = All_X_ifidf[nb_X_Train:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1iaUcwo4iSN",
        "colab_type": "text"
      },
      "source": [
        "Onehot encode the classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFu-rKUaoDyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "y_onehot = onehot_encoder.fit_transform(y.reshape(-1,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnFSfbhHeCob",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Create NN using Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DWMw4LFeE3v",
        "colab_type": "code",
        "outputId": "1cf7e484-9261-4872-8259-50e29c8159f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, BatchNormalization, GaussianNoise\n",
        "from keras.regularizers import l2\n",
        "from keras.optimizers import Adagrad\n",
        "from keras.constraints import max_norm\n",
        "\n",
        "model = Sequential([\n",
        "  # Input layer\n",
        "  Dense(\n",
        "    1024,\n",
        "    use_bias=False,\n",
        "    input_shape=(X.shape[1],),\n",
        "    kernel_constraint=max_norm(3.),\n",
        "  ),\n",
        "  BatchNormalization(),\n",
        "  Activation('relu'),\n",
        "\n",
        "  # Output layer\n",
        "  Dense(\n",
        "    20,\n",
        "    use_bias=False\n",
        "  ),\n",
        "  BatchNormalization(),\n",
        "  Activation('softmax'),\n",
        "])\n",
        "\n",
        "model.compile(Adagrad(learning_rate=0.003),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(X, y_onehot, epochs=1, batch_size=64)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "70000/70000 [==============================] - 53s 754us/step - loss: 1.8131 - accuracy: 0.4997\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x1807fa04d08>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIW3xGQLu5_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(Kaggle_Test_X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK4me5_d73i8",
        "colab_type": "text"
      },
      "source": [
        "# Write output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "692a59fe-f19f-4e71-f997-211a9b886776",
        "id": "FBiRnGcN44ZI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_kaggle = onehot_encoder.inverse_transform(y_pred)\n",
        "y_kaggle = y_kaggle.squeeze()\n",
        "print(y_kaggle.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXdwcImjv9rD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_and_save_submission(predictions, file_name=\"submission.csv\"):\n",
        "    ids = [i for i in range(len(predictions))]\n",
        "    sub_df = pd.DataFrame(data=list(zip(ids, predictions)), columns=[\"Id\",\"Category\"])\n",
        "    sub_df.to_csv(file_name, index=False)\n",
        "\n",
        "create_and_save_submission(y_kaggle)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}